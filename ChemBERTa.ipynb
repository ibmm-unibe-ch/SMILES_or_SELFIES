{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fingerprint correlation reproduction\n",
        "## Install external libraries"
      ],
      "metadata": {
        "id": "-tsc_JI1hI90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Ub6r9w7_Ag",
        "outputId": "75c594bb-c6a5-42f6-d421-0360392d6255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.9/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rdkit) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit) (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selfies in /usr/local/lib/python3.9/dist-packages (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install transformers\n",
        "!pip install rdkit\n",
        "!pip install selfies"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "BPXOUZvohish"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykFEgov_2Bih"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "from scipy.spatial.distance import cdist, cosine\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from rdkit import Chem\n",
        "\n",
        "import logging\n",
        "import random\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import selfies\n",
        "\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "\n",
        "SEED = 6217"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling functions"
      ],
      "metadata": {
        "id": "4P-km-NHi_1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k7xeMN70bZX"
      },
      "outputs": [],
      "source": [
        "def canonize_smile(input_str: str, remove_identities: bool = True) -> str:\n",
        "    mol = Chem.MolFromSmiles(input_str)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    if remove_identities:\n",
        "        [a.SetAtomMapNum(0) for a in mol.GetAtoms()]\n",
        "    return Chem.MolToSmiles(mol)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random sampling"
      ],
      "metadata": {
        "id": "Bjq1FZRAjHFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_synonym(\n",
        "    seed: int = None, min_size: int = 5, max_size: int = 30\n",
        ") -> Tuple[str, str, str, str]:\n",
        "    random.seed(seed)\n",
        "    found_fitting = False\n",
        "    alphabet = (\n",
        "        selfies.get_semantic_robust_alphabet()\n",
        "    )  # Gets the alphabet of robust symbols\n",
        "    while not found_fitting:\n",
        "        size = random.randint(min_size, max_size)\n",
        "        rnd_selfies = \"\".join(random.sample(list(alphabet), size))\n",
        "        rnd_smiles = selfies.decoder(rnd_selfies)\n",
        "        rnd_smiles = rnd_smiles.replace(\"-1\", \"-\").replace(\"+1\", \"+\")\n",
        "        canon_smiles = canonize_smile(rnd_smiles)\n",
        "        rnd_selfies = selfies.encoder(rnd_smiles)\n",
        "        canon_selfies = selfies.encoder(canon_smiles)\n",
        "        if (canon_smiles != rnd_smiles) and (canon_selfies != rnd_selfies):\n",
        "            found_fitting = True\n",
        "    return rnd_smiles, canon_smiles, rnd_selfies, canon_selfies\n",
        "\n",
        "\n",
        "def sample_random_molecules(\n",
        "    amount: int = 1000, overcompensation_factor: int = 1.1\n",
        ") -> pd.DataFrame:\n",
        "    molecule_list = []\n",
        "    for seed in range(SEED, int(SEED + amount * overcompensation_factor)):\n",
        "        molecule_list.append(sample_synonym(seed))\n",
        "    df = pd.DataFrame(\n",
        "        molecule_list,\n",
        "        columns=[\"rnd_smiles\", \"canon_smiles\", \"rnd_selfies\", \"canon_selfies\"],\n",
        "    )\n",
        "    df.drop_duplicates([\"canon_smiles\"], inplace=True)\n",
        "    if df.shape[0] < amount:\n",
        "        logging.info(\n",
        "            f\"Overcompensation factor of {overcompensation_factor} was not enough.\"\n",
        "        )\n",
        "        return sample_random_molecules(amount, overcompensation_factor * 1.1)\n",
        "    return df.iloc[:amount]"
      ],
      "metadata": {
        "id": "-6sNqebBjKq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubChem sampling"
      ],
      "metadata": {
        "id": "6KyWqRvfjODa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_mols_fromPubChem():\n",
        "    # dataset taken from https://ibm.ent.box.com/v/MoLFormer-data (\"pubchem-smiles-canonical.zip\")\n",
        "    smi_df = pd.read_csv(\n",
        "        \"/content/drive/MyDrive/Datasets/smi_test.smi\", header=None, delimiter=r\"\\s+\"\n",
        "    )\n",
        "    return smi_df.iloc[:1000]"
      ],
      "metadata": {
        "id": "FxpQsoz5D3-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity computation functions"
      ],
      "metadata": {
        "id": "kcg5WOhkjgEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_correlation(distances1, distances2, prefix: Optional[str] = None):\n",
        "    pearson = pearsonr(distances1, distances2)\n",
        "    spearman = spearmanr(distances1, distances2)\n",
        "    pearson_string = f\"{prefix} Pearson\" if prefix else \"Pearson\"\n",
        "    spearman_string = f\"{prefix} Spearman\" if prefix else \"Spearman\"\n",
        "    return {pearson_string: pearson, spearman_string: spearman}"
      ],
      "metadata": {
        "id": "ppGdy_aEjvi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chemical fingerprint similarity"
      ],
      "metadata": {
        "id": "Mr28ifBmjpIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebUTP-lgR8s5"
      },
      "outputs": [],
      "source": [
        "def get_pairwise_chemical_similarities(mol_start, mol_end):\n",
        "    # https://www.rdkit.org/docs/GettingStartedInPython.html#morgan-fingerprints-circular-fingerprints\n",
        "    morgan_start = AllChem.GetMorganFingerprint(mol_start, 2)  # 2 is closest to ECFP\n",
        "    morgan_end = AllChem.GetMorganFingerprint(mol_end, 2)  # 2 is closest to ECFP\n",
        "    morgan_dice = DataStructs.DiceSimilarity(morgan_start, morgan_end)\n",
        "    morgan_start = AllChem.GetMorganFingerprintAsBitVect(mol_start, 2)\n",
        "    morgan_end = AllChem.GetMorganFingerprintAsBitVect(mol_end, 2)\n",
        "    morgan_tanimoto = DataStructs.FingerprintSimilarity(morgan_start, morgan_end)\n",
        "    rdkit_start = Chem.RDKFingerprint(mol_start)\n",
        "    rdkit_end = Chem.RDKFingerprint(mol_end)\n",
        "    rdkit_distance = DataStructs.FingerprintSimilarity(rdkit_start, rdkit_end)\n",
        "    return morgan_dice, morgan_tanimoto, rdkit_distance\n",
        "\n",
        "\n",
        "def get_chemical_similarities(SMILES_starts, SMILES_ends):\n",
        "    mol_starts = [Chem.MolFromSmiles(SMILES_start) for SMILES_start in SMILES_starts]\n",
        "    mol_ends = [Chem.MolFromSmiles(SMILES_end) for SMILES_end in SMILES_ends]\n",
        "    similarities = np.array(\n",
        "        [\n",
        "            get_pairwise_chemical_similarities(mol_start, mol_end)\n",
        "            for (mol_start, mol_end) in zip(mol_starts, mol_ends)\n",
        "        ]\n",
        "    )\n",
        "    return similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model embedding distance"
      ],
      "metadata": {
        "id": "luSfHDHtj5IS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJljW6gX0fSw"
      },
      "outputs": [],
      "source": [
        "def compute_distances(start: pd.Series, end: pd.Series) -> Tuple[float, float, float]:\n",
        "    euclid = cdist([start], [end], \"euclid\")\n",
        "    manhattan = cdist([start], [end], \"cityblock\")\n",
        "    cos = cosine(start, end)\n",
        "    return euclid[0][0], manhattan[0][0], cos\n",
        "\n",
        "\n",
        "def get_embeddings(tokenizer, SMILES_starts_nn, SMILES_ends_nn):\n",
        "    SMILES_starts = np.array(SMILES_starts_nn)\n",
        "    SMILES_ends = np.array(SMILES_ends_nn)\n",
        "    mol_starts_tokenized = [\n",
        "        tokenizer.encode(SMILES_start, return_tensors=\"pt\")\n",
        "        for SMILES_start in SMILES_starts\n",
        "    ]\n",
        "    mol_ends_tokenized = [\n",
        "        tokenizer.encode(SMILES_end, return_tensors=\"pt\") for SMILES_end in SMILES_ends\n",
        "    ]\n",
        "    # https://stackoverflow.com/questions/63323464/how-to-get-the-correct-embedding-from-roberta-transformers\n",
        "    mol_starts_out = [model(input)[-1][-1] for input in mol_starts_tokenized]\n",
        "    mol_ends_out = [model(input)[-1][-1] for input in mol_ends_tokenized]\n",
        "    return mol_starts_out, mol_ends_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4dHzXPM10zT"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "lAx-QTNlkdeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read in data from file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDNVDXOZ12qs",
        "outputId": "02569f67-ff9e-4854-c6c1-d553682ea1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample molecules"
      ],
      "metadata": {
        "id": "fpYcMTD6koxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKQaCOEm13dl",
        "outputId": "39537bbf-d879-4004-9e14-af34c650dcdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[15:35:29] WARNING: not removing hydrogen atom without neighbors\n",
            "[15:35:30] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [P+]=[C-]C=CN=[B+]\n",
            "1            [O-]S=[B+]\n",
            "2                 S#COI\n",
            "3                 [H]Br\n",
            "4                   O=N\n",
            "Name: rnd_smiles, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# sample random mols without file\n",
        "rndm_mols = sample_random_molecules(1000)\n",
        "rndm_smiles = rndm_mols.loc[:,\"rnd_smiles\"]\n",
        "# sample mols from PubChem\n",
        "#rndm_mols = sample_mols_fromPubChem()\n",
        "#rndm_smiles = rndm_mols.loc[:1000, 1]\n",
        "\n",
        "# Only sample 300 molecules because of Colab size restrictions\n",
        "smiles_starts = rndm_smiles.head(300)\n",
        "smiles_ends = rndm_smiles.tail(300)\n",
        "print(smiles_starts.head(5))\n",
        "\n",
        "# Else to use all 1000/2 molecules\n",
        "# top = int(np.ceil(rndm_smiles.shape[0] / 2))\n",
        "# bottom = int(rndm_smiles.shape[0] - top)\n",
        "# smiles_starts = rndm_smiles.head(top)\n",
        "# smiles_ends = rndm_smiles.tail(bottom)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get embeddings"
      ],
      "metadata": {
        "id": "bwcFSCcollnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing different models\n",
        "#    model 1\n",
        "#model = AutoModelForMaskedLM.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
        "#    model2 : ChemBERTa_zinc250k_v2_40k supposedly better\n",
        "#model = AutoModelForMaskedLM.from_pretrained(\"seyonec/ChemBERTa_zinc250k_v2_40k\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa_zinc250k_v2_40k\")\n",
        "#    model 3 biggest and newest: \"DeepChem/ChemBERTa-77M-MLM\"\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
        "\n",
        "# get embeddings of SMILES\n",
        "smiles_starts_embs, smiles_ends_embs = get_embeddings(\n",
        "    tokenizer, smiles_starts, smiles_ends\n",
        ")\n",
        "print(len(smiles_starts_embs))\n",
        "# turn to numpy arrays\n",
        "smiles_starts_embs = [em.detach().numpy() for em in smiles_starts_embs]\n",
        "smiles_ends_embs = [em.detach().numpy() for em in smiles_ends_embs]\n",
        "# print(f\"First molecule embedding: {smiles_starts_embs[0]}\"\")"
      ],
      "metadata": {
        "id": "VA1qYsaElqfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906c8a54-7ea0-4096-9915-a871c5556b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute distances and similarities"
      ],
      "metadata": {
        "id": "pm-ATplUltQq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI4PSsgnkDhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e9d238-feeb-40d4-90d3-7837c0eda548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "600\n",
            "Pairs tested:  300\n"
          ]
        }
      ],
      "source": [
        "# get chemical similarities of SMILES\n",
        "chemical_similarities = get_chemical_similarities(smiles_starts, smiles_ends)\n",
        "morgan_dice = chemical_similarities[:, 0]\n",
        "morgan_tanimoto = chemical_similarities[:, 1]\n",
        "rdkit_distance = chemical_similarities[:, 2]\n",
        "\n",
        "print(len(smiles_starts_embs))\n",
        "print(len(smiles_starts_embs[0][-1]))\n",
        "\n",
        "# compute pairwise distances of embeddings\n",
        "distances = [\n",
        "    compute_distances(emb_start[-1], emb_end[-1])\n",
        "    for (emb_start, emb_end) in zip(smiles_starts_embs, smiles_ends_embs)\n",
        "]\n",
        "print(\"Pairs tested: \", len(distances))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute correlations"
      ],
      "metadata": {
        "id": "bigW7ikpl7ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances_des = [\"euclid\", \"manhattan\", \"cosine\"]\n",
        "sims = [morgan_dice, morgan_tanimoto, rdkit_distance]\n",
        "sims_des = [\"morgan_dice\", \"morgan_tanimoto\", \"rdkit_distance\"]\n",
        "for iti, sim in enumerate(sims):\n",
        "    for pos, distance_de in enumerate(distances_des):\n",
        "        print(f\"correlation {sims_des[iti]} and {distance_de}\")\n",
        "        cor = get_correlation([distance[pos] for distance in distances], sim)\n",
        "        print(cor)"
      ],
      "metadata": {
        "id": "zZ6ltWwKmAPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc05fc0-0e5e-401f-ffb6-d2e0a58732bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correlation morgan_dice and euclid\n",
            "{'Pearson': PearsonRResult(statistic=-0.19492488134786223, pvalue=0.0006869791654329817), 'Spearman': SignificanceResult(statistic=-0.17230598099496452, pvalue=0.0027498935040403245)}\n",
            "correlation morgan_dice and manhattan\n",
            "{'Pearson': PearsonRResult(statistic=-0.17186273233780103, pvalue=0.002821210615453053), 'Spearman': SignificanceResult(statistic=-0.15296802798017836, pvalue=0.007952953471339402)}\n",
            "correlation morgan_dice and cosine\n",
            "{'Pearson': PearsonRResult(statistic=-0.17786320031667996, pvalue=0.001984683383943188), 'Spearman': SignificanceResult(statistic=-0.25665405186281814, pvalue=6.716996455108489e-06)}\n",
            "correlation morgan_tanimoto and euclid\n",
            "{'Pearson': PearsonRResult(statistic=-0.1976050433435225, pvalue=0.0005767140560968044), 'Spearman': SignificanceResult(statistic=-0.17207334167933616, pvalue=0.0027871173966223625)}\n",
            "correlation morgan_tanimoto and manhattan\n",
            "{'Pearson': PearsonRResult(statistic=-0.18552710897375962, pvalue=0.0012462471880986291), 'Spearman': SignificanceResult(statistic=-0.1657450153902911, pvalue=0.003992668665043612)}\n",
            "correlation morgan_tanimoto and cosine\n",
            "{'Pearson': PearsonRResult(statistic=-0.1595815407602836, pvalue=0.005600996109981463), 'Spearman': SignificanceResult(statistic=-0.23098965352293516, pvalue=5.370024390392315e-05)}\n",
            "correlation rdkit_distance and euclid\n",
            "{'Pearson': PearsonRResult(statistic=-0.09674102597008956, pvalue=0.09441913143215609), 'Spearman': SignificanceResult(statistic=-0.07300071863248928, pvalue=0.20737591440027367)}\n",
            "correlation rdkit_distance and manhattan\n",
            "{'Pearson': PearsonRResult(statistic=-0.06672629588501694, pvalue=0.24924174714085934), 'Spearman': SignificanceResult(statistic=-0.036427109219485825, pvalue=0.5296694260646193)}\n",
            "correlation rdkit_distance and cosine\n",
            "{'Pearson': PearsonRResult(statistic=-0.17367094346358902, pvalue=0.0025404469228339213), 'Spearman': SignificanceResult(statistic=-0.22778258574027357, pvalue=6.853917076944783e-05)}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}